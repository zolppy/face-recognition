{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6fdaf45"
      },
      "source": [
        "!pip install -q kagglehub tensorflow keras matplotlib\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"hemantsoni042/celebrity-images-for-face-recognition\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58b216e6"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "\n",
        "image_dir = os.path.join(path, 'celebrities_images')\n",
        "celebrity_folders = [d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))]\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "for celebrity_name in celebrity_folders:\n",
        "    celebrity_folder_path = os.path.join(image_dir, celebrity_name)\n",
        "    for image_file in os.listdir(celebrity_folder_path):\n",
        "        image_path = os.path.join(celebrity_folder_path, image_file)\n",
        "        image_paths.append(image_path)\n",
        "        labels.append(celebrity_name)\n",
        "\n",
        "unique_labels = sorted(list(set(labels)))\n",
        "label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
        "\n",
        "images = []\n",
        "numerical_labels = []\n",
        "image_size = (100, 100)\n",
        "\n",
        "for image_path, label in zip(image_paths, labels):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, image_size)\n",
        "        img = img / 255.0\n",
        "        images.append(img)\n",
        "        numerical_labels.append(label_to_id[label])\n",
        "\n",
        "images = np.array(images)\n",
        "numerical_labels = np.array(numerical_labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, numerical_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=len(unique_labels))\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=len(unique_labels))\n",
        "\n",
        "print(f\"Number of images loaded: {len(images)}\")\n",
        "print(f\"Shape of images array: {images.shape}\")\n",
        "print(f\"Shape of numerical labels array: {numerical_labels.shape}\")\n",
        "print(f\"Number of unique celebrities: {len(unique_labels)}\")\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "print(f\"Shape of y_train_one_hot: {y_train_one_hot.shape}\")\n",
        "print(f\"Shape of y_test_one_hot: {y_test_one_hot.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9e4aa7f"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "771e224d"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train_one_hot,\n",
        "                    epochs=10,\n",
        "                    validation_data=(X_test, y_test_one_hot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa917348"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def recognize_face(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image from {image_path}\")\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    img_with_detections = img.copy()\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_img = img[y:y+h, x:x+w]\n",
        "        face_img = cv2.resize(face_img, image_size)\n",
        "        face_img = face_img / 255.0\n",
        "        face_img = np.expand_dims(face_img, axis=0)\n",
        "\n",
        "        predictions = model.predict(face_img)\n",
        "        predicted_class_id = np.argmax(predictions)\n",
        "        predicted_label = unique_labels[predicted_class_id]\n",
        "\n",
        "        cv2.rectangle(img_with_detections, (x, y), (x+w, y+h), (255, 0, 0), 1)\n",
        "        cv2.putText(img_with_detections, predicted_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "    return img_with_detections\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd31af95"
      },
      "source": [
        "sample_image_array = (X_test[sample_image_index] * 255).astype(np.uint8)\n",
        "sample_image_label_id = y_test[sample_image_index]\n",
        "sample_image_label = unique_labels[sample_image_label_id]\n",
        "\n",
        "temp_image_path = \"temp_test_image.jpg\"\n",
        "cv2.imwrite(temp_image_path, cv2.cvtColor(sample_image_array, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "recognized_image = recognize_face(temp_image_path)\n",
        "\n",
        "if recognized_image is not None:\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    plt.imshow(cv2.cvtColor(recognized_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Detected Faces and Recognized Identities\\n(Original Label: {sample_image_label})\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    os.remove(temp_image_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}